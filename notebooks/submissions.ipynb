{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone git@github.com:CristianApost0L/AML-Competition-Notebook.git\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/AML-Competition-Notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Checkpoints for both submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "folder_id = \"1N7KO7zFjJ8PvtwABlRW7Ry5QsBlafTy8\"\n",
    "!gdown --folder $folder_id -O ./checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Ensemble\n",
    "\n",
    "Submission 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -r /kaggle/input/aml-irp/pytorch/default/11/AML-Competition-Notebook/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Add src directory to Python path\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# This assumes the notebook is in the 'notebooks' directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- 1. Import Modules ---\n",
    "from src.irp_refiner import config\n",
    "from src.irp_refiner.utils import set_seed\n",
    "from src.irp_refiner.data_processing import load_and_clean_data\n",
    "from src.irp_refiner.models.irp import IRPTranslator\n",
    "from src.irp_refiner.models.mlp import ResidualMLP\n",
    "from src.irp_refiner.ensembling import EnsembleWrapper\n",
    "from src.irp_refiner.evaluation import evaluate_retrieval\n",
    "from src.irp_refiner.baseline_utils import load_data, generate_submission\n",
    "from src.irp_refiner.training import train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- 2. Setup ---\n",
    "worker_init_fn = set_seed(config.SEED)\n",
    "DEVICE = config.DEVICE\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Load and Clean Data\n",
    "X_train_np_cleaned, Y_train_np_cleaned = load_and_clean_data(\n",
    "    config.TRAIN_DATA_PATH, config.NOISE_THRESHOLD\n",
    ")\n",
    "\n",
    "!mkdir \"checkpoints\"\n",
    "\n",
    "# 2. Initialize KFold\n",
    "kf = KFold(n_splits=config.K_FOLDS, shuffle=True, random_state=config.SEED)\n",
    "\n",
    "# 3. K-Fold Training Loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_np_cleaned)):\n",
    "    print(\"\\\\n\" + \"=\"*80)\n",
    "    print(f\"=============== FOLD {fold+1}/{config.K_FOLDS} ===============\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # --- Split data for this fold ---\n",
    "    X_train_fold, X_val_fold = X_train_np_cleaned[train_idx], X_train_np_cleaned[val_idx]\n",
    "    Y_train_fold, Y_val_fold = Y_train_np_cleaned[train_idx], Y_train_np_cleaned[val_idx]\n",
    "\n",
    "    # --- IRP Stage ---\n",
    "    print(f\"--- FOLD {fold+1}: IRP Stage ---\")\n",
    "    anchor_indices = np.random.choice(len(X_train_fold), config.K_ANCHORS, replace=False)\n",
    "    X_anchor = X_train_fold[anchor_indices]\n",
    "    Y_anchor = Y_train_fold[anchor_indices]\n",
    "\n",
    "    scaler_X = StandardScaler().fit(X_anchor)\n",
    "    scaler_Y = StandardScaler().fit(Y_anchor)\n",
    "\n",
    "    irp_translator_fold = IRPTranslator(\n",
    "        scaler_X, scaler_Y, \n",
    "        omega=config.IRP_OMEGA, delta=config.IRP_DELTA, \n",
    "        ridge=config.IRP_RIDGE, verbose=False\n",
    "    )\n",
    "    irp_translator_fold.fit(X_anchor, Y_anchor)\n",
    "    print(f\"   âœ“ IRP translator for fold {fold+1} fitted.\")\n",
    "\n",
    "    irp_path = f\"{config.CHECKPOINT_DIR}irp_translator_fold_{fold}.pkl\"\n",
    "    joblib.dump(irp_translator_fold, irp_path)\n",
    "    print(f\"   âœ“ IRP translator saved to {irp_path}\")\n",
    "\n",
    "    X_train_IRP_fold = torch.from_numpy(irp_translator_fold.translate(X_train_fold)).float()\n",
    "    X_val_IRP_fold = torch.from_numpy(irp_translator_fold.translate(X_val_fold)).float()\n",
    "    print(f\"   âœ“ Train and Val data transformed for fold {fold+1}.\")\n",
    "\n",
    "    # --- DataLoader Stage ---\n",
    "    train_ds_fold = TensorDataset(X_train_IRP_fold, torch.from_numpy(Y_train_fold).float())\n",
    "    val_ds_fold = TensorDataset(X_val_IRP_fold, torch.from_numpy(Y_val_fold).float())\n",
    "\n",
    "    train_loader_fold = DataLoader(train_ds_fold, batch_size=config.BATCH_SIZE, shuffle=True, worker_init_fn=worker_init_fn)\n",
    "    val_loader_fold = DataLoader(val_ds_fold, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # --- Model Training Stage ---\n",
    "    print(f\"--- FOLD {fold+1}: MLP Refiner Training Stage ---\")\n",
    "    model_fold = ResidualMLP(\n",
    "        input_dim=config.D_X, output_dim=config.D_Y, hidden_dim=config.HIDDEN_DIM,\n",
    "        num_hidden_layers=config.NUM_HIDDEN_LAYERS, dropout_p=config.DROPOUT_P\n",
    "    ).to(config.DEVICE)\n",
    "\n",
    "    model_path_fold = f\"{config.CHECKPOINT_DIR}mlp_fold_{fold}.pth\"\n",
    "\n",
    "    train_model(\n",
    "        model_fold, train_loader_fold, val_loader_fold, config.DEVICE,\n",
    "        epochs=config.EPOCHS, lr=config.LR, save_path=model_path_fold,\n",
    "        patience=config.EARLY_STOP_PATIENCE, min_delta=config.MIN_IMPROVEMENT_DELTA,\n",
    "        resume=False \n",
    "    )\n",
    "\n",
    "    # --- Clean up memory ---\n",
    "    del model_fold, train_loader_fold, val_loader_fold, X_train_IRP_fold, X_val_IRP_fold\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"K-Fold Training Complete. All models saved.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- 4. Load the K-Fold Ensemble ---\n",
    "print(\"Loading K-Fold models and IRP translators...\")\n",
    "\n",
    "model_paths = [f\"{config.CHECKPOINT_DIR}mlp_fold_{f}.pth\" for f in range(config.K_FOLDS)]\n",
    "irp_paths = [f\"{config.CHECKPOINT_DIR}irp_translator_fold_{f}.pkl\" for f in range(config.K_FOLDS)]\n",
    "\n",
    "# Check if the files exist first\n",
    "if not os.path.exists(model_paths[0]):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"ERROR: Model file not found at {model_paths[0]}\")\n",
    "    print(\"Please run 'python scripts/train.py' to train the K-Fold models before running this notebook.\")\n",
    "    print(\"=\"*80)\n",
    "    ensemble_wrapper = None\n",
    "else:\n",
    "    ensemble_wrapper = EnsembleWrapper(model_paths, irp_paths, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- 5. Evaluate Ensemble on Validation Set ---\n",
    "if ensemble_wrapper:\n",
    "    print(\"\\nGenerating ensemble predictions for the validation set...\")\n",
    "    \n",
    "    # IMPORTANT: We pass the RAW (non-IRP) validation data.\n",
    "    # The EnsembleWrapper handles the IRP step for each model internally.\n",
    "    y_val_pred_ensemble = ensemble_wrapper.translate(X_val_np)\n",
    "    \n",
    "    print(\"Predictions generated. Running evaluation...\")\n",
    "\n",
    "    # Prepare ground truth\n",
    "    gt_indices_val = np.arange(len(Y_val_np))\n",
    "\n",
    "    # Run evaluation\n",
    "    results = evaluate_retrieval(\n",
    "        y_val_pred_ensemble,\n",
    "        Y_val_np,\n",
    "        gt_indices_val,\n",
    "        batch_size=config.BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- ENSEMBLE EVALUATION RESULTS (on hold-out set) ---\")\n",
    "    for metric, value in results.items():\n",
    "        if 'recall' in metric:\n",
    "            print(f\"  {metric}: {value:.2%}\")\n",
    "        else:\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "else:\n",
    "    print(\"Skipping evaluation because ensemble was not loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Ensemble Submission File\n",
    "\n",
    "Now we use the loaded `ensemble_wrapper` to process the actual test data and generate a submission file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "if ensemble_wrapper:\n",
    "    print(\"\\n--- 6. Generating Ensemble Submission ---\")\n",
    "    \n",
    "    # 1. Load test data\n",
    "    print(\"Loading test data...\")\n",
    "    test_data = load_data(config.TEST_DATA_PATH)\n",
    "    test_embds_raw_np = test_data['captions/embeddings']\n",
    "    print(f\"Test data loaded: {len(test_embds_raw_np)} samples.\")\n",
    "\n",
    "    # 2. Generate predictions using the ensemble\n",
    "    print(\"Applying ensemble pipeline to test data... (this may take a moment)\")\n",
    "    pred_embds_ensemble = ensemble_wrapper.translate(test_embds_raw_np)\n",
    "    print(\"Ensemble predictions generated.\")\n",
    "\n",
    "    # 3. Save submission file\n",
    "    submission_filename = 'submission_Ensemble_Notebook.csv'\n",
    "    generate_submission(test_data['captions/ids'], pred_embds_ensemble, submission_filename)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"âœ… Submission file '{submission_filename}' generated.\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"Skipping submission generation because ensemble was not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Direct Model Experimentation\n",
    " \n",
    "Submission 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- 1. Setup and Imports ---\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Add src directory to Python path\n",
    "# This assumes the notebook is in the 'notebooks' directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "\n",
    "# Import all our custom modules\n",
    "from src import config\n",
    "from src import baseline_utils\n",
    "from src import evaluation\n",
    "from src import training\n",
    "from src import ensembling\n",
    "from src.data_processing import load_and_prep_data_direct\n",
    "from src.models import mlp_direct\n",
    "from src.utils import set_seed\n",
    "\n",
    "print(\"All modules imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- 2. Configuration ---\n",
    "worker_init_fn = set_seed(config.SEED)\n",
    "DEVICE = config.DEVICE\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Kaggle data path: {config.TRAIN_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- 3. Load, Clean, and Split Data ---\n",
    "# This single function replicates the entire data prep workflow from Cell 4.\n",
    "# It handles merging (if enabled), noise cleaning, and splitting.\n",
    "print(\"Loading, cleaning, and splitting data...\")\n",
    "\n",
    "(X_train, y_train, X_val, y_val, \n",
    " val_text_embd, val_img_embd_unique, val_label_gt) = load_and_prep_data_direct(\n",
    "    train_path=config.TRAIN_DATA_PATH,\n",
    "    coco_path=config.MY_DATA_PATH,\n",
    "    use_coco=config.USE_COCO_DATASET,\n",
    "    noise_threshold=config.NOISE_THRESHOLD,\n",
    "    val_split_ratio=config.VAL_SIZE,\n",
    "    random_seed=config.SEED\n",
    ")\n",
    "\n",
    "print(\"\\n--- Data Loading Complete ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val (queries) shape: {X_val.shape}\")\n",
    "print(f\"val_img_embd_unique (gallery) shape: {val_img_embd_unique.shape}\")\n",
    "print(f\"val_label_gt (ground truth) shape: {val_label_gt.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- 4. Create DataLoaders ---\n",
    "# (As seen in the original notebook's Cell 8)\n",
    "train_dl_std = DataLoader(\n",
    "    TensorDataset(X_train, y_train), \n",
    "    batch_size=config.MODERN_HPARAMS['batch_size'], \n",
    "    shuffle=True\n",
    ")\n",
    "val_dl_std = DataLoader(\n",
    "    TensorDataset(X_val, y_val), \n",
    "    batch_size=config.MODERN_HPARAMS['batch_size'], \n",
    "    shuffle=False\n",
    ")\n",
    "print(\"DataLoaders created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 5a. Train Model I (ResidualMLP, No-Norm) ---\n",
    "print(\"--- 1. Training Modello I (ResidualMLP, No-Norm) ---\")\n",
    "model_I = mlp_direct.ResidualMLP_BN(\n",
    "    input_dim=1024,         # <-- FIX: Was config.D_X (1536)\n",
    "    output_dim=1536,        # <-- FIX: Was config.D_Y (1536)\n",
    "    num_layers=2, \n",
    "    dropout=0.4\n",
    ").to(DEVICE)\n",
    "\n",
    "model_I = training.train_standard_direct(\n",
    "    model_I, train_dl_std, val_dl_std, \n",
    "    epochs=100, \n",
    "    lr=config.LR, \n",
    "    save_path=f\"{config.CHECKPOINT_DIR}model_I_ResidualMLP_NoNorm.pth\", \n",
    "    patience=10, \n",
    "    use_norm_in_loss=False, \n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# %%\n",
    "# --- 5b. Train Model C (SwiGLU, No-Norm) ---\n",
    "print(\"\\n--- 2. Training Modello C (SwiGLU, No-Norm) ---\")\n",
    "model_C = mlp_direct.SwiGLUMLP(\n",
    "    input_dim=1024,         # <-- FIX: Was config.D_X (1536)\n",
    "    output_dim=1536,        # <-- FIX: Was config.D_Y (1536)\n",
    "    num_layers=2, \n",
    "    dropout=0.4\n",
    ").to(DEVICE)\n",
    "\n",
    "model_C = training.train_standard_direct(\n",
    "    model_C, train_dl_std, val_dl_std, \n",
    "    epochs=100, \n",
    "    lr=config.LR, \n",
    "    save_path=f\"{config.CHECKPOINT_DIR}model_C_SwiGLU_NoNorm.pth\", \n",
    "    patience=10, \n",
    "    use_norm_in_loss=False, \n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# %%\n",
    "# --- 5c. Train Model Modern (Ensemble) ---\n",
    "print(\"\\n--- 3. Training Modello Modern (Ensemble) ---\")\n",
    "models_Modern = [\n",
    "    training.train_single_modern_model(\n",
    "        seed, X_train, y_train, X_val, y_val, \n",
    "        hparams=config.MODERN_HPARAMS, \n",
    "        patience=10, \n",
    "        device=DEVICE\n",
    "    )\n",
    "    for seed in config.MODERN_SEEDS\n",
    "]\n",
    "\n",
    "# %%\n",
    "# --- 5d. Train Model E (Diverse Ensemble) ---\n",
    "print(\"\\n--- 4. Training Modello E (Diverse Ensemble) ---\")\n",
    "# This function trains 3 different models and returns them in a list\n",
    "models_E = training.create_direct_ensemble(\n",
    "    X_train, y_train, X_val, y_val, DEVICE\n",
    ")\n",
    "\n",
    "# %%\n",
    "print(\"âœ… All model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"--- Avvio Valutazione Comparativa ---\")\n",
    "\n",
    "# 1. Create Wrappers for evaluation\n",
    "wrapper_I = evaluation.MLPWrapper(model_I, DEVICE)\n",
    "wrapper_C = evaluation.MLPWrapper(model_C, DEVICE)\n",
    "wrapper_Modern = ensembling.DirectEnsembleWrapper(models_Modern, DEVICE)\n",
    "wrapper_E = ensembling.DirectEnsembleWrapper(models_E, DEVICE)\n",
    "\n",
    "# 2. Generate prediction embeddings (once)\n",
    "print(\"\\nâ†’ Generating prediction embeddings...\")\n",
    "emb_I = wrapper_I.translate(val_text_embd)\n",
    "emb_C = wrapper_C.translate(val_text_embd)\n",
    "emb_Modern = wrapper_Modern.translate(val_text_embd)\n",
    "emb_E = wrapper_E.translate(val_text_embd)\n",
    "\n",
    "# 3. Normalize Ground Truth embeddings (once)\n",
    "print(\"\\nâ†’ Normalizing ground truth embeddings...\")\n",
    "# Full gallery for N-vs-M retrieval\n",
    "gallery_emb_norm = F.normalize(val_img_embd_unique.float().to(DEVICE), p=2, dim=1)\n",
    "# Paired gallery for N-vs-N retrieval\n",
    "paired_emb_norm = F.normalize(y_val.float().to(DEVICE), p=2, dim=1)\n",
    "\n",
    "# 4. Run Full Retrieval (N vs. M Gallery)\n",
    "print(\"\\nðŸ”¥ VALUTAZIONE FULL RETRIEVAL (CLIP-style, N vs M)\")\n",
    "metrics_I_full = evaluation.evaluate_retrieval_full(emb_I, gallery_emb_norm, val_label_gt, device=DEVICE)\n",
    "metrics_C_full = evaluation.evaluate_retrieval_full(emb_C, gallery_emb_norm, val_label_gt, device=DEVICE)\n",
    "metrics_Modern_full = evaluation.evaluate_retrieval_full(emb_Modern, gallery_emb_norm, val_label_gt, device=DEVICE)\n",
    "metrics_E_full = evaluation.evaluate_retrieval_full(emb_E, gallery_emb_norm, val_label_gt, device=DEVICE)\n",
    "\n",
    "# 5. Run In-Batch Retrieval (N vs. N)\n",
    "print(\"\\nðŸ”¥ VALUTAZIONE IN-BATCH (Competizione Style, N vs N)\")\n",
    "metrics_I_ib = evaluation.aml_inbatch_retrieval(torch.from_numpy(emb_I).to(DEVICE), paired_emb_norm)\n",
    "metrics_C_ib = evaluation.aml_inbatch_retrieval(torch.from_numpy(emb_C).to(DEVICE), paired_emb_norm)\n",
    "metrics_Modern_ib = evaluation.aml_inbatch_retrieval(torch.from_numpy(emb_Modern).to(DEVICE), paired_emb_norm)\n",
    "metrics_E_ib = evaluation.aml_inbatch_retrieval(torch.from_numpy(emb_E).to(DEVICE), paired_emb_norm)\n",
    "\n",
    "# 6. Print Report\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"          ðŸ“Š RIEPILOGO FINALE: FULL vs IN-BATCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def print_full_and_inbatch(name, full, ib):\n",
    "    print(f\"\\nðŸ”µ {name}\")\n",
    "    print(\"- FULL RETRIEVAL (N vs M Gallery)\")\n",
    "    print(f\"  Recall@1:   {full.get('recall@1', 0):.4f}\")\n",
    "    print(f\"  Recall@5:   {full.get('recall@5', 0):.4f}\")\n",
    "    print(f\"  MRR:        {full.get('mrr', 0):.4f}\")\n",
    "    print(\"- IN-BATCH RETRIEVAL (N vs N)\")\n",
    "    print(f\"  Recall@1:   {ib.get('r1', 0):.4f}\")\n",
    "    print(f\"  Recall@5:   {ib.get('r5', 0):.4f}\")\n",
    "    print(f\"  MRR:        {ib.get('mrr', 0):.4f}\")\n",
    "\n",
    "print_full_and_inbatch(\"Modello I (ResidualMLP)\", metrics_I_full, metrics_I_ib)\n",
    "print_full_and_inbatch(\"Modello C (SwiGLU)\", metrics_C_full, metrics_C_ib)\n",
    "print_full_and_inbatch(\"Modello Modern (Ensemble)\", metrics_Modern_full, metrics_Modern_ib)\n",
    "print_full_and_inbatch(\"Modello E (Diverse Ensemble)\", metrics_E_full, metrics_E_ib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"--- Generazione Submission ---\")\n",
    "\n",
    "# --- CHOOSE YOUR WINNING MODEL ---\n",
    "# The Diverse Ensemble (E) performed best in the evaluation.\n",
    "wrapper_submission = wrapper_E\n",
    "# ---------------------------------\n",
    "\n",
    "print(f\"Using model: Diverse Ensemble (E)\")\n",
    "\n",
    "# 1. Load test data\n",
    "print(\"Loading test data...\")\n",
    "test_data = baseline_utils.load_data(config.TEST_DATA_PATH)\n",
    "X_test_np = test_data['captions/embeddings']\n",
    "test_ids = test_data['captions/ids']\n",
    "print(f\"Test data loaded: {len(X_test_np)} samples.\")\n",
    "\n",
    "# 2. Generate predictions\n",
    "print(\"Generating predictions on the test set...\")\n",
    "# The wrapper handles normalization internally\n",
    "y_test_pred = wrapper_submission.translate(X_test_np, batch_size=512)\n",
    "\n",
    "# 3. Save submission file\n",
    "submission_filename = \"submission_direct_ensemble_E.csv\"\n",
    "baseline_utils.generate_submission(test_ids, y_test_pred, submission_filename)\n",
    "\n",
    "print(f\"\\nâœ… Submission salvata: {submission_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14220991,
     "isSourceIdPinned": false,
     "sourceId": 117959,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 503951,
     "modelInstanceId": 488525,
     "sourceId": 648678,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 503951,
     "modelInstanceId": 488525,
     "sourceId": 648765,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 503951,
     "modelInstanceId": 488525,
     "sourceId": 648770,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 503951,
     "modelInstanceId": 488525,
     "sourceId": 648802,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
