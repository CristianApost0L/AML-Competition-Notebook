{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":648678,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":488525,"modelId":503951},{"sourceId":648765,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":488525,"modelId":503951},{"sourceId":648770,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":488525,"modelId":503951},{"sourceId":648802,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":488525,"modelId":503951}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# K-Fold Ensemble Evaluation\n\nSubmission 2","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/aml-irp/pytorch/default/12/AML-Competition-Notebook\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install gdown\nfolder_id = \"1N7KO7zFjJ8PvtwABlRW7Ry5QsBlafTy8\"\n!gdown --folder $folder_id -O ./checkpoints","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -r /kaggle/input/aml-irp/pytorch/default/11/AML-Competition-Notebook/requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# Add src directory to Python path\nimport sys\nimport os\nimport gc\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport joblib\n\n# This assumes the notebook is in the 'notebooks' directory\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 1. Import Modules ---\nfrom src.irp_refiner import config\nfrom src.irp_refiner.utils import set_seed\nfrom src.irp_refiner.data_processing import load_and_clean_data\nfrom src.irp_refiner.models.irp import IRPTranslator\nfrom src.irp_refiner.models.mlp import ResidualMLP\nfrom src.irp_refiner.ensembling import EnsembleWrapper\nfrom src.irp_refiner.evaluation import evaluate_retrieval\nfrom src.irp_refiner.baseline_utils import load_data, generate_submission\nfrom src.irp_refiner.training import train_model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 2. Setup ---\nworker_init_fn = set_seed(config.SEED)\nDEVICE = config.DEVICE\nprint(f\"Using device: {DEVICE}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Load and Clean Data\nX_train_np_cleaned, Y_train_np_cleaned = load_and_clean_data(\n    config.TRAIN_DATA_PATH, config.NOISE_THRESHOLD\n)\n\n!mkdir \"checkpoints\"\n\n# 2. Initialize KFold\nkf = KFold(n_splits=config.K_FOLDS, shuffle=True, random_state=config.SEED)\n\n# 3. K-Fold Training Loop\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train_np_cleaned)):\n    print(\"\\\\n\" + \"=\"*80)\n    print(f\"=============== FOLD {fold+1}/{config.K_FOLDS} ===============\")\n    print(\"=\"*80)\n\n    # --- Split data for this fold ---\n    X_train_fold, X_val_fold = X_train_np_cleaned[train_idx], X_train_np_cleaned[val_idx]\n    Y_train_fold, Y_val_fold = Y_train_np_cleaned[train_idx], Y_train_np_cleaned[val_idx]\n\n    # --- IRP Stage ---\n    print(f\"--- FOLD {fold+1}: IRP Stage ---\")\n    anchor_indices = np.random.choice(len(X_train_fold), config.K_ANCHORS, replace=False)\n    X_anchor = X_train_fold[anchor_indices]\n    Y_anchor = Y_train_fold[anchor_indices]\n\n    scaler_X = StandardScaler().fit(X_anchor)\n    scaler_Y = StandardScaler().fit(Y_anchor)\n\n    irp_translator_fold = IRPTranslator(\n        scaler_X, scaler_Y, \n        omega=config.IRP_OMEGA, delta=config.IRP_DELTA, \n        ridge=config.IRP_RIDGE, verbose=False\n    )\n    irp_translator_fold.fit(X_anchor, Y_anchor)\n    print(f\"   âœ“ IRP translator for fold {fold+1} fitted.\")\n\n    irp_path = f\"{config.CHECKPOINT_DIR}irp_translator_fold_{fold}.pkl\"\n    joblib.dump(irp_translator_fold, irp_path)\n    print(f\"   âœ“ IRP translator saved to {irp_path}\")\n\n    X_train_IRP_fold = torch.from_numpy(irp_translator_fold.translate(X_train_fold)).float()\n    X_val_IRP_fold = torch.from_numpy(irp_translator_fold.translate(X_val_fold)).float()\n    print(f\"   âœ“ Train and Val data transformed for fold {fold+1}.\")\n\n    # --- DataLoader Stage ---\n    train_ds_fold = TensorDataset(X_train_IRP_fold, torch.from_numpy(Y_train_fold).float())\n    val_ds_fold = TensorDataset(X_val_IRP_fold, torch.from_numpy(Y_val_fold).float())\n\n    train_loader_fold = DataLoader(train_ds_fold, batch_size=config.BATCH_SIZE, shuffle=True, worker_init_fn=worker_init_fn)\n    val_loader_fold = DataLoader(val_ds_fold, batch_size=config.BATCH_SIZE, shuffle=False)\n\n    # --- Model Training Stage ---\n    print(f\"--- FOLD {fold+1}: MLP Refiner Training Stage ---\")\n    model_fold = ResidualMLP(\n        input_dim=config.D_X, output_dim=config.D_Y, hidden_dim=config.HIDDEN_DIM,\n        num_hidden_layers=config.NUM_HIDDEN_LAYERS, dropout_p=config.DROPOUT_P\n    ).to(config.DEVICE)\n\n    model_path_fold = f\"{config.CHECKPOINT_DIR}mlp_fold_{fold}.pth\"\n\n    train_model(\n        model_fold, train_loader_fold, val_loader_fold, config.DEVICE,\n        epochs=config.EPOCHS, lr=config.LR, save_path=model_path_fold,\n        patience=config.EARLY_STOP_PATIENCE, min_delta=config.MIN_IMPROVEMENT_DELTA,\n        resume=False \n    )\n\n    # --- Clean up memory ---\n    del model_fold, train_loader_fold, val_loader_fold, X_train_IRP_fold, X_val_IRP_fold\n    gc.collect()\n    torch.cuda.empty_cache()\n\nprint(\"\\\\n\" + \"=\"*80)\nprint(\"K-Fold Training Complete. All models saved.\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 4. Load the K-Fold Ensemble ---\nprint(\"Loading K-Fold models and IRP translators...\")\n\nmodel_paths = [f\"{config.CHECKPOINT_DIR}mlp_fold_{f}.pth\" for f in range(config.K_FOLDS)]\nirp_paths = [f\"{config.CHECKPOINT_DIR}irp_translator_fold_{f}.pkl\" for f in range(config.K_FOLDS)]\n\n# Check if the files exist first\nif not os.path.exists(model_paths[0]):\n    print(\"=\"*80)\n    print(f\"ERROR: Model file not found at {model_paths[0]}\")\n    print(\"Please run 'python scripts/train.py' to train the K-Fold models before running this notebook.\")\n    print(\"=\"*80)\n    ensemble_wrapper = None\nelse:\n    ensemble_wrapper = EnsembleWrapper(model_paths, irp_paths, DEVICE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 5. Evaluate Ensemble on Validation Set ---\nif ensemble_wrapper:\n    print(\"\\nGenerating ensemble predictions for the validation set...\")\n    \n    # IMPORTANT: We pass the RAW (non-IRP) validation data.\n    # The EnsembleWrapper handles the IRP step for each model internally.\n    y_val_pred_ensemble = ensemble_wrapper.translate(X_val_np)\n    \n    print(\"Predictions generated. Running evaluation...\")\n\n    # Prepare ground truth\n    gt_indices_val = np.arange(len(Y_val_np))\n\n    # Run evaluation\n    results = evaluate_retrieval(\n        y_val_pred_ensemble,\n        Y_val_np,\n        gt_indices_val,\n        batch_size=config.BATCH_SIZE\n    )\n\n    print(\"\\n--- ENSEMBLE EVALUATION RESULTS (on hold-out set) ---\")\n    for metric, value in results.items():\n        if 'recall' in metric:\n            print(f\"  {metric}: {value:.2%}\")\n        else:\n            print(f\"  {metric}: {value:.4f}\")\n    print(\"-------------------------------------------------------\")\nelse:\n    print(\"Skipping evaluation because ensemble was not loaded.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Generate Ensemble Submission File\n\nNow we use the loaded `ensemble_wrapper` to process the actual test data and generate a submission file.\n","metadata":{}},{"cell_type":"code","source":"# %%\nif ensemble_wrapper:\n    print(\"\\n--- 6. Generating Ensemble Submission ---\")\n    \n    # 1. Load test data\n    print(\"Loading test data...\")\n    test_data = load_data(config.TEST_DATA_PATH)\n    test_embds_raw_np = test_data['captions/embeddings']\n    print(f\"Test data loaded: {len(test_embds_raw_np)} samples.\")\n\n    # 2. Generate predictions using the ensemble\n    print(\"Applying ensemble pipeline to test data... (this may take a moment)\")\n    pred_embds_ensemble = ensemble_wrapper.translate(test_embds_raw_np)\n    print(\"Ensemble predictions generated.\")\n\n    # 3. Save submission file\n    submission_filename = 'submission_Ensemble_Notebook.csv'\n    generate_submission(test_data['captions/ids'], pred_embds_ensemble, submission_filename)\n    \n    print(\"\\n\" + \"=\"*50)\n    print(f\"âœ… Submission file '{submission_filename}' generated.\")\n    print(\"=\"*50)\nelse:\n    print(\"Skipping submission generation because ensemble was not loaded.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # Direct Model Experimentation\n \nSubmission 1","metadata":{}},{"cell_type":"code","source":"# --- 1. Setup and Imports ---\nimport sys\nimport os\nimport gc\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Add src directory to Python path\n# This assumes the notebook is in the 'notebooks' directory\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n\n# Import all our custom modules\nfrom src import config\nfrom src import baseline_utils\nfrom src import evaluation\nfrom src import training\nfrom src import ensembling\nfrom src.data_processing import load_and_prep_data_direct\nfrom src.models import mlp_direct\nfrom src.utils import set_seed\n\nprint(\"All modules imported successfully.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 2. Configuration ---\nworker_init_fn = set_seed(config.SEED)\nDEVICE = config.DEVICE\nprint(f\"Using device: {DEVICE}\")\nprint(f\"Kaggle data path: {config.TRAIN_DATA_PATH}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 3. Load, Clean, and Split Data ---\n# This single function replicates the entire data prep workflow from Cell 4.\n# It handles merging (if enabled), noise cleaning, and splitting.\nprint(\"Loading, cleaning, and splitting data...\")\n\n(X_train, y_train, X_val, y_val, \n val_text_embd, val_img_embd_unique, val_label_gt) = load_and_prep_data_direct(\n    train_path=config.TRAIN_DATA_PATH,\n    coco_path=config.MY_DATA_PATH,\n    use_coco=config.USE_COCO_DATASET,\n    noise_threshold=config.NOISE_THRESHOLD,\n    val_split_ratio=config.VAL_SIZE,\n    random_seed=config.SEED\n)\n\nprint(\"\\n--- Data Loading Complete ---\")\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_val (queries) shape: {X_val.shape}\")\nprint(f\"val_img_embd_unique (gallery) shape: {val_img_embd_unique.shape}\")\nprint(f\"val_label_gt (ground truth) shape: {val_label_gt.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 4. Create DataLoaders ---\n# (As seen in the original notebook's Cell 8)\ntrain_dl_std = DataLoader(\n    TensorDataset(X_train, y_train), \n    batch_size=config.MODERN_HPARAMS['batch_size'], \n    shuffle=True\n)\nval_dl_std = DataLoader(\n    TensorDataset(X_val, y_val), \n    batch_size=config.MODERN_HPARAMS['batch_size'], \n    shuffle=False\n)\nprint(\"DataLoaders created.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ## 5. Model Training","metadata":{}},{"cell_type":"code","source":"\n# --- 5a. Train Model I (ResidualMLP, No-Norm) ---\nprint(\"--- 1. Training Modello I (ResidualMLP, No-Norm) ---\")\nmodel_I = mlp_direct.ResidualMLP_BN(\n    input_dim=1024,         # <-- FIX: Was config.D_X (1536)\n    output_dim=1536,        # <-- FIX: Was config.D_Y (1536)\n    num_layers=2, \n    dropout=0.4\n).to(DEVICE)\n\nmodel_I = training.train_standard_direct(\n    model_I, train_dl_std, val_dl_std, \n    epochs=100, \n    lr=config.LR, \n    save_path=f\"{config.CHECKPOINT_DIR}model_I_ResidualMLP_NoNorm.pth\", \n    patience=10, \n    use_norm_in_loss=False, \n    device=DEVICE\n)\n\n# %%\n# --- 5b. Train Model C (SwiGLU, No-Norm) ---\nprint(\"\\n--- 2. Training Modello C (SwiGLU, No-Norm) ---\")\nmodel_C = mlp_direct.SwiGLUMLP(\n    input_dim=1024,         # <-- FIX: Was config.D_X (1536)\n    output_dim=1536,        # <-- FIX: Was config.D_Y (1536)\n    num_layers=2, \n    dropout=0.4\n).to(DEVICE)\n\nmodel_C = training.train_standard_direct(\n    model_C, train_dl_std, val_dl_std, \n    epochs=100, \n    lr=config.LR, \n    save_path=f\"{config.CHECKPOINT_DIR}model_C_SwiGLU_NoNorm.pth\", \n    patience=10, \n    use_norm_in_loss=False, \n    device=DEVICE\n)\n\n# %%\n# --- 5c. Train Model Modern (Ensemble) ---\nprint(\"\\n--- 3. Training Modello Modern (Ensemble) ---\")\nmodels_Modern = [\n    training.train_single_modern_model(\n        seed, X_train, y_train, X_val, y_val, \n        hparams=config.MODERN_HPARAMS, \n        patience=10, \n        device=DEVICE\n    )\n    for seed in config.MODERN_SEEDS\n]\n\n# %%\n# --- 5d. Train Model E (Diverse Ensemble) ---\nprint(\"\\n--- 4. Training Modello E (Diverse Ensemble) ---\")\n# This function trains 3 different models and returns them in a list\nmodels_E = training.create_direct_ensemble(\n    X_train, y_train, X_val, y_val, DEVICE\n)\n\n# %%\nprint(\"âœ… All model training complete.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Model Evaluation","metadata":{}},{"cell_type":"code","source":"print(\"--- Avvio Valutazione Comparativa ---\")\n\n# 1. Create Wrappers for evaluation\nwrapper_I = evaluation.MLPWrapper(model_I, DEVICE)\nwrapper_C = evaluation.MLPWrapper(model_C, DEVICE)\nwrapper_Modern = ensembling.DirectEnsembleWrapper(models_Modern, DEVICE)\nwrapper_E = ensembling.DirectEnsembleWrapper(models_E, DEVICE)\n\n# 2. Generate prediction embeddings (once)\nprint(\"\\nâ†’ Generating prediction embeddings...\")\nemb_I = wrapper_I.translate(val_text_embd)\nemb_C = wrapper_C.translate(val_text_embd)\nemb_Modern = wrapper_Modern.translate(val_text_embd)\nemb_E = wrapper_E.translate(val_text_embd)\n\n# 3. Normalize Ground Truth embeddings (once)\nprint(\"\\nâ†’ Normalizing ground truth embeddings...\")\n# Full gallery for N-vs-M retrieval\ngallery_emb_norm = F.normalize(val_img_embd_unique.float().to(DEVICE), p=2, dim=1)\n# Paired gallery for N-vs-N retrieval\npaired_emb_norm = F.normalize(y_val.float().to(DEVICE), p=2, dim=1)\n\n# 4. Run Full Retrieval (N vs. M Gallery)\nprint(\"\\nðŸ”¥ VALUTAZIONE FULL RETRIEVAL (CLIP-style, N vs M)\")\nmetrics_I_full = evaluation.evaluate_retrieval_full(emb_I, gallery_emb_norm, val_label_gt, device=DEVICE)\nmetrics_C_full = evaluation.evaluate_retrieval_full(emb_C, gallery_emb_norm, val_label_gt, device=DEVICE)\nmetrics_Modern_full = evaluation.evaluate_retrieval_full(emb_Modern, gallery_emb_norm, val_label_gt, device=DEVICE)\nmetrics_E_full = evaluation.evaluate_retrieval_full(emb_E, gallery_emb_norm, val_label_gt, device=DEVICE)\n\n# 5. Run In-Batch Retrieval (N vs. N)\nprint(\"\\nðŸ”¥ VALUTAZIONE IN-BATCH (Competizione Style, N vs N)\")\nmetrics_I_ib = evaluation.aml_inbatch_retrieval(torch.from_numpy(emb_I).to(DEVICE), paired_emb_norm)\nmetrics_C_ib = evaluation.aml_inbatch_retrieval(torch.from_numpy(emb_C).to(DEVICE), paired_emb_norm)\nmetrics_Modern_ib = evaluation.aml_inbatch_retrieval(torch.from_numpy(emb_Modern).to(DEVICE), paired_emb_norm)\nmetrics_E_ib = evaluation.aml_inbatch_retrieval(torch.from_numpy(emb_E).to(DEVICE), paired_emb_norm)\n\n# 6. Print Report\nprint(\"\\n\\n\" + \"=\"*80)\nprint(\"          ðŸ“Š RIEPILOGO FINALE: FULL vs IN-BATCH\")\nprint(\"=\"*80)\n\ndef print_full_and_inbatch(name, full, ib):\n    print(f\"\\nðŸ”µ {name}\")\n    print(\"- FULL RETRIEVAL (N vs M Gallery)\")\n    print(f\"  Recall@1:   {full.get('recall@1', 0):.4f}\")\n    print(f\"  Recall@5:   {full.get('recall@5', 0):.4f}\")\n    print(f\"  MRR:        {full.get('mrr', 0):.4f}\")\n    print(\"- IN-BATCH RETRIEVAL (N vs N)\")\n    print(f\"  Recall@1:   {ib.get('r1', 0):.4f}\")\n    print(f\"  Recall@5:   {ib.get('r5', 0):.4f}\")\n    print(f\"  MRR:        {ib.get('mrr', 0):.4f}\")\n\nprint_full_and_inbatch(\"Modello I (ResidualMLP)\", metrics_I_full, metrics_I_ib)\nprint_full_and_inbatch(\"Modello C (SwiGLU)\", metrics_C_full, metrics_C_ib)\nprint_full_and_inbatch(\"Modello Modern (Ensemble)\", metrics_Modern_full, metrics_Modern_ib)\nprint_full_and_inbatch(\"Modello E (Diverse Ensemble)\", metrics_E_full, metrics_E_ib)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Generate Submission","metadata":{}},{"cell_type":"code","source":"print(\"--- Generazione Submission ---\")\n\n# --- CHOOSE YOUR WINNING MODEL ---\n# The Diverse Ensemble (E) performed best in the evaluation.\nwrapper_submission = wrapper_E\n# ---------------------------------\n\nprint(f\"Using model: Diverse Ensemble (E)\")\n\n# 1. Load test data\nprint(\"Loading test data...\")\ntest_data = baseline_utils.load_data(config.TEST_DATA_PATH)\nX_test_np = test_data['captions/embeddings']\ntest_ids = test_data['captions/ids']\nprint(f\"Test data loaded: {len(X_test_np)} samples.\")\n\n# 2. Generate predictions\nprint(\"Generating predictions on the test set...\")\n# The wrapper handles normalization internally\ny_test_pred = wrapper_submission.translate(X_test_np, batch_size=512)\n\n# 3. Save submission file\nsubmission_filename = \"submission_direct_ensemble_E.csv\"\nbaseline_utils.generate_submission(test_ids, y_test_pred, submission_filename)\n\nprint(f\"\\nâœ… Submission salvata: {submission_filename}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}