{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":648025,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":488525,"modelId":503951},{"sourceId":648053,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":488525,"modelId":503951},{"sourceId":648062,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":488525,"modelId":503951},{"sourceId":648551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":488525,"modelId":503951},{"sourceId":648678,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":488525,"modelId":503951}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# K-Fold Ensemble Evaluation Notebook\n\nThis notebook loads the K-Fold models and IRP translators (trained by `scripts/train.py`) to:\n1.  Instantiate an `EnsembleWrapper`.\n2.  Evaluate the ensemble's performance on a hold-out validation set.\n3.  Generate a final `submission.csv` using the ensemble.","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/aml-irp/pytorch/default/9/AML-Competition-Notebook\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install gdown\nfolder_id = \"1N7KO7zFjJ8PvtwABlRW7Ry5QsBlafTy8\"\n!gdown --folder $folder_id -O ./checkpoints","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -r /kaggle/input/aml-irp/pytorch/default/6/AML-Competition-Notebook/requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# Add src directory to Python path\nimport sys\nimport os\nimport gc\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport joblib\n\n# This assumes the notebook is in the 'notebooks' directory\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 1. Import Modules ---\nfrom src.irp_refiner import config\nfrom src.irp_refiner.utils import set_seed\nfrom src.irp_refiner.data_processing import load_and_clean_data\nfrom src.irp_refiner.models.irp import IRPTranslator\nfrom src.irp_refiner.models.mlp import ResidualMLP\nfrom src.irp_refiner.ensembling import EnsembleWrapper\nfrom src.irp_refiner.evaluation import evaluate_retrieval\nfrom src.irp_refiner.baseline_utils import load_data, generate_submission\nfrom src.irp_refiner.training import train_model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 2. Setup ---\nworker_init_fn = set_seed(config.SEED)\nDEVICE = config.DEVICE\nprint(f\"Using device: {DEVICE}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Load and Clean Data\nX_train_np_cleaned, Y_train_np_cleaned = load_and_clean_data(\n    config.TRAIN_DATA_PATH, config.NOISE_THRESHOLD\n)\n\n!mkdir \"checkpoints\"\n\n# 2. Initialize KFold\nkf = KFold(n_splits=config.K_FOLDS, shuffle=True, random_state=config.SEED)\n\n# 3. K-Fold Training Loop\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X_train_np_cleaned)):\n    print(\"\\\\n\" + \"=\"*80)\n    print(f\"=============== FOLD {fold+1}/{config.K_FOLDS} ===============\")\n    print(\"=\"*80)\n\n    # --- Split data for this fold ---\n    X_train_fold, X_val_fold = X_train_np_cleaned[train_idx], X_train_np_cleaned[val_idx]\n    Y_train_fold, Y_val_fold = Y_train_np_cleaned[train_idx], Y_train_np_cleaned[val_idx]\n\n    # --- IRP Stage ---\n    print(f\"--- FOLD {fold+1}: IRP Stage ---\")\n    anchor_indices = np.random.choice(len(X_train_fold), config.K_ANCHORS, replace=False)\n    X_anchor = X_train_fold[anchor_indices]\n    Y_anchor = Y_train_fold[anchor_indices]\n\n    scaler_X = StandardScaler().fit(X_anchor)\n    scaler_Y = StandardScaler().fit(Y_anchor)\n\n    irp_translator_fold = IRPTranslator(\n        scaler_X, scaler_Y, \n        omega=config.IRP_OMEGA, delta=config.IRP_DELTA, \n        ridge=config.IRP_RIDGE, verbose=False\n    )\n    irp_translator_fold.fit(X_anchor, Y_anchor)\n    print(f\"   ✓ IRP translator for fold {fold+1} fitted.\")\n\n    irp_path = f\"{config.CHECKPOINT_DIR}irp_translator_fold_{fold}.pkl\"\n    joblib.dump(irp_translator_fold, irp_path)\n    print(f\"   ✓ IRP translator saved to {irp_path}\")\n\n    X_train_IRP_fold = torch.from_numpy(irp_translator_fold.translate(X_train_fold)).float()\n    X_val_IRP_fold = torch.from_numpy(irp_translator_fold.translate(X_val_fold)).float()\n    print(f\"   ✓ Train and Val data transformed for fold {fold+1}.\")\n\n    # --- DataLoader Stage ---\n    train_ds_fold = TensorDataset(X_train_IRP_fold, torch.from_numpy(Y_train_fold).float())\n    val_ds_fold = TensorDataset(X_val_IRP_fold, torch.from_numpy(Y_val_fold).float())\n\n    train_loader_fold = DataLoader(train_ds_fold, batch_size=config.BATCH_SIZE, shuffle=True, worker_init_fn=worker_init_fn)\n    val_loader_fold = DataLoader(val_ds_fold, batch_size=config.BATCH_SIZE, shuffle=False)\n\n    # --- Model Training Stage ---\n    print(f\"--- FOLD {fold+1}: MLP Refiner Training Stage ---\")\n    model_fold = ResidualMLP(\n        input_dim=config.D_X, output_dim=config.D_Y, hidden_dim=config.HIDDEN_DIM,\n        num_hidden_layers=config.NUM_HIDDEN_LAYERS, dropout_p=config.DROPOUT_P\n    ).to(config.DEVICE)\n\n    model_path_fold = f\"{config.CHECKPOINT_DIR}mlp_fold_{fold}.pth\"\n\n    train_model(\n        model_fold, train_loader_fold, val_loader_fold, config.DEVICE,\n        epochs=config.EPOCHS, lr=config.LR, save_path=model_path_fold,\n        patience=config.EARLY_STOP_PATIENCE, min_delta=config.MIN_IMPROVEMENT_DELTA,\n        resume=False \n    )\n\n    # --- Clean up memory ---\n    del model_fold, train_loader_fold, val_loader_fold, X_train_IRP_fold, X_val_IRP_fold\n    gc.collect()\n    torch.cuda.empty_cache()\n\nprint(\"\\\\n\" + \"=\"*80)\nprint(\"K-Fold Training Complete. All models saved.\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 4. Load the K-Fold Ensemble ---\nprint(\"Loading K-Fold models and IRP translators...\")\n\nmodel_paths = [f\"{config.CHECKPOINT_DIR}mlp_fold_{f}.pth\" for f in range(config.K_FOLDS)]\nirp_paths = [f\"{config.CHECKPOINT_DIR}irp_translator_fold_{f}.pkl\" for f in range(config.K_FOLDS)]\n\n# Check if the files exist first\nif not os.path.exists(model_paths[0]):\n    print(\"=\"*80)\n    print(f\"ERROR: Model file not found at {model_paths[0]}\")\n    print(\"Please run 'python scripts/train.py' to train the K-Fold models before running this notebook.\")\n    print(\"=\"*80)\n    ensemble_wrapper = None\nelse:\n    ensemble_wrapper = EnsembleWrapper(model_paths, irp_paths, DEVICE)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%\n# --- 5. Evaluate Ensemble on Validation Set ---\nif ensemble_wrapper:\n    print(\"\\nGenerating ensemble predictions for the validation set...\")\n    \n    # IMPORTANT: We pass the RAW (non-IRP) validation data.\n    # The EnsembleWrapper handles the IRP step for each model internally.\n    y_val_pred_ensemble = ensemble_wrapper.translate(X_val_np)\n    \n    print(\"Predictions generated. Running evaluation...\")\n\n    # Prepare ground truth\n    gt_indices_val = np.arange(len(Y_val_np))\n\n    # Run evaluation\n    results = evaluate_retrieval(\n        y_val_pred_ensemble,\n        Y_val_np,\n        gt_indices_val,\n        batch_size=config.BATCH_SIZE\n    )\n\n    print(\"\\n--- ENSEMBLE EVALUATION RESULTS (on hold-out set) ---\")\n    for metric, value in results.items():\n        if 'recall' in metric:\n            print(f\"  {metric}: {value:.2%}\")\n        else:\n            print(f\"  {metric}: {value:.4f}\")\n    print(\"-------------------------------------------------------\")\nelse:\n    print(\"Skipping evaluation because ensemble was not loaded.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Generate Ensemble Submission File\n\nNow we use the loaded `ensemble_wrapper` to process the actual test data and generate a submission file.\n","metadata":{}},{"cell_type":"code","source":"# %%\nif ensemble_wrapper:\n    print(\"\\n--- 6. Generating Ensemble Submission ---\")\n    \n    # 1. Load test data\n    print(\"Loading test data...\")\n    test_data = load_data(config.TEST_DATA_PATH)\n    test_embds_raw_np = test_data['captions/embeddings']\n    print(f\"Test data loaded: {len(test_embds_raw_np)} samples.\")\n\n    # 2. Generate predictions using the ensemble\n    print(\"Applying ensemble pipeline to test data... (this may take a moment)\")\n    pred_embds_ensemble = ensemble_wrapper.translate(test_embds_raw_np)\n    print(\"Ensemble predictions generated.\")\n\n    # 3. Save submission file\n    submission_filename = 'submission_Ensemble_Notebook.csv'\n    generate_submission(test_data['captions/ids'], pred_embds_ensemble, submission_filename)\n    \n    print(\"\\n\" + \"=\"*50)\n    print(f\"✅ Submission file '{submission_filename}' generated.\")\n    print(\"=\"*50)\nelse:\n    print(\"Skipping submission generation because ensemble was not loaded.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}